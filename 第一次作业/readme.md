首先作业1是根据CS231n课程SVM章节的课后作业实现的，包括分类器和损失函数加上交叉验证等，再加上引用博客
处理 MNIST 数据集，然后将处理过的数据传入分类器进行分类（其实就是相当于把以前分类器进行了封装，处理
后导入）不过这个分类器的整个实现过程当初仔细看过。
作业2是根据要求使用Scikit-learn的分类器，查看文档后，将数据处理后进行直接调用
两个作业的正确率当特征为像素点时都是0.85以上
当特征为灰度直方图时，正确率不到0.30，我觉得是因为直方图没有体现像素位置信息吧
博客可能写的可能比较简单。。。因为我不喜欢写博客，我有些东西如果想重复的去记忆，我都会写很多注释，然
后存起来反复的去看。。反正很少基本没写过博客
而且目前让我写某个算法原理，我觉得我真正清清楚楚搞明白并且能讲出来的目前只有线性回归这一种最简单了，
因为我觉得算法这东西确实需要反反复复的去看才可以真正的理解，我也看了西瓜书，看了博客，看了机器学习视
频，我觉得每一次看都会多理解一点东西，从最开始只是明白他是做什么的，到慢慢的怎么做到的，到最后数学底
层的推导，没有很多遍的看我觉得是吃不透的。同时线性分类比如逻辑回归牵扯的东西太多，从为什么线性回归的
损失函数不适合线性分类，到损失函数模型线性回归是平方差，线性分类是最大似然估计+概率模型背后的原因，所
以我感觉并没有吃透这个原理，SVM就更难了，所以这次博文就写一写入门的线性回归吧。
博文是在CSDN上写的，这里是网页链接：https://blog.csdn.net/qq_43298462/article/details/95377997